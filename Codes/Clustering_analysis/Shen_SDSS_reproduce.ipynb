{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import ascii\n",
    "from MyToolkit import *\n",
    "from Clustering_module import *\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "import matplotlib as mpl\n",
    "\n",
    "DP2_DIRECTORY = \"/home/vibin/MyFolder/WorkDesk/DP2/\"\n",
    "\n",
    "# def make_rand_from_dist(red_col, n_samples):            #Make a random z distribution from the data z distribution\n",
    "#     bins = [2.90 + i*0.005 for i in range(500)]         #using inverse transform sampling\n",
    "#     hist, edges = np.histogram(red_col, bins=bins)\n",
    "#     bin_widths = np.diff(edges)\n",
    "#     cdf = np.cumsum(hist * bin_widths) / np.sum(hist * bin_widths)\n",
    "#     #plt.stairs(cdf, bins)\n",
    "\n",
    "#     # Generate new z values that follow the histogram distribution\n",
    "#     uniform_values = np.random.rand(n_samples)\n",
    "#     bin_indices = np.searchsorted(cdf, uniform_values)\n",
    "#     bin_edges = edges[bin_indices-1]\n",
    "#     bin_diff = edges[bin_indices] - edges[bin_indices-1]\n",
    "#     bin_weights = (uniform_values - cdf[bin_indices-1]) / (cdf[bin_indices] - cdf[bin_indices-1])\n",
    "\n",
    "#     new_z_values = bin_edges + bin_weights * bin_diff\n",
    "\n",
    "#     return new_z_values\n",
    "\n",
    "def make_shen_random_catalog_v3(ra_col, dec_col, red_col, init_level, mult):\n",
    "    ### First made a random distribution of points in the whole sky, then chose\n",
    "    ### only those points that fall in the SDSS map \n",
    "    num_quasars = len(ra_col) * mult\n",
    "\n",
    "    nside2 = 2 ** (init_level+1)\n",
    "    nside3 = 2 ** (init_level+3)\n",
    "    nside4 = 2 ** (init_level+4)\n",
    "    nside5 = 2 ** (init_level+6)\n",
    "\n",
    "    npixels = hp.nside2npix(nside2)\n",
    "    hp_map = np.zeros(npixels)\n",
    "\n",
    "    occ_pix_high = hp.ang2pix(nside2, ra_col, dec_col, lonlat=True)\n",
    "    hp_map[occ_pix_high] = 1\n",
    "    hp_map = hp.ud_grade(hp_map, nside3)\n",
    "    occ_pix_high = np.where(hp_map == 1)\n",
    "\n",
    "    occ_pix_high = np.unique(hp.get_all_neighbours(nside3, occ_pix_high))\n",
    "    occ_pix_high = np.delete(occ_pix_high, np.where(occ_pix_high == -1))\n",
    "    hp_map[occ_pix_high] = 1\n",
    "    hp_map = hp.ud_grade(hp_map, nside4)\n",
    "    occ_pix_high = np.where(hp_map == 1)\n",
    "\n",
    "    occ_pix_high = np.unique(hp.get_all_neighbours(nside4, occ_pix_high))\n",
    "    occ_pix_high = np.delete(occ_pix_high, np.where(occ_pix_high == -1))\n",
    "    hp_map[occ_pix_high] = 1\n",
    "    hp_map = hp.ud_grade(hp_map, nside5)\n",
    "    occ_pix_high = np.where(hp_map == 1)\n",
    "\n",
    "    occ_pix_high = np.unique(hp.get_all_neighbours(nside5, occ_pix_high))\n",
    "    occ_pix_high = np.delete(occ_pix_high, np.where(occ_pix_high == -1))\n",
    "    hp_map[occ_pix_high] = 1\n",
    "\n",
    "    # map_now = healpix_sky_map_ps1_cover_area(ra_col, dec_col, init_level)\n",
    "    # map_now = map_now[1]\n",
    "    map_now = hp_map\n",
    "    nside = hp.get_nside(map_now)\n",
    "\n",
    "    pixels_with_data = np.shape(np.where(map_now == 1))[1]\n",
    "    area_data_pixels = pixels_with_data * hp.nside2pixarea(hp.get_nside(map_now), degrees=True)\n",
    "    print(\"Mask area = \", area_data_pixels)\n",
    "\n",
    "    ind = np.where(np.arange(num_quasars) > -1)\n",
    "    rand_ra = np.zeros(num_quasars)\n",
    "    rand_dec = np.zeros(num_quasars)\n",
    "\n",
    "    while True:\n",
    "        rand_ra[ind] = np.random.uniform(0, 360, len(ind[0]))\n",
    "        rand_dec[ind] = np.degrees(np.arcsin(np.random.uniform(-0.5, 1, len(ind[0]))))     \n",
    "\n",
    "        pix_of_points = hp.ang2pix(nside, np.absolute(np.radians(rand_dec) - np.pi/2), np.radians(rand_ra))\n",
    "        ind = np.where(map_now[pix_of_points] == 0)\n",
    "\n",
    "        if(len(ind[0]) == 0):\n",
    "            break \n",
    "\n",
    "    rand_red = make_rand_from_dist(red_col, num_quasars)\n",
    "\n",
    "    return rand_ra, rand_dec, rand_red\n",
    "\n",
    "def make_shen_random_catalog_v2(ra_col, dec_col, red_col, init_level, mult):\n",
    "    ### First made a random distribution of points in the whole sky, then chose\n",
    "    ### only those points that fall in the SDSS map \n",
    "    num_quasars = len(ra_col) * mult\n",
    "\n",
    "    nside = 2 ** init_level\n",
    "\n",
    "    map_now = healpix_sky_map_ps1_cover_area(ra_col, dec_col, init_level)\n",
    "    map_now = map_now[1]\n",
    "\n",
    "    ind = np.where(np.arange(num_quasars) > -1)\n",
    "    rand_ra = np.zeros(num_quasars)\n",
    "    rand_dec = np.zeros(num_quasars)\n",
    "\n",
    "    while True:\n",
    "        rand_ra[ind] = np.random.uniform(0, 360, len(ind[0]))\n",
    "        rand_dec[ind] = np.degrees(np.arcsin(np.random.uniform(-0.5, 1, len(ind[0]))))     \n",
    "\n",
    "        pix_of_points = hp.ang2pix(nside, np.absolute(np.radians(rand_dec) - np.pi/2), np.radians(rand_ra))\n",
    "        ind = np.where(map_now[pix_of_points] == 0)\n",
    "\n",
    "        if(len(ind[0]) == 0):\n",
    "            break \n",
    "\n",
    "    rand_red = make_rand_from_dist(red_col, num_quasars)\n",
    "\n",
    "    return rand_ra, rand_dec, rand_red\n",
    "\n",
    "def make_shen_random_catalog(ra_col, dec_col, red_col, init_level, resol_upgrd, mult):\n",
    "    ### Healpy pixelated the data catalog to find the rough footprint, appropriate healpy level found\n",
    "    ### from the graph of coverage area vs level. Then increased the pixelation and chosen random\n",
    "    ### pixels to assign points to its centre.\n",
    "    ### \n",
    "    num_quasars = len(ra_col) * mult\n",
    "\n",
    "    map_now = healpix_sky_map_ps1_cover_area(ra_col, dec_col, init_level)\n",
    "    map_now = map_now[1]\n",
    "\n",
    "    map_then = hp.pixelfunc.ud_grade(map_now, 2 ** resol_upgrd)\n",
    "\n",
    "    map_random = np.zeros_like(map_then)\n",
    "    val_pos = np.where(map_then != 0)\n",
    "    num_pix = len(val_pos[0])\n",
    "\n",
    "    rand = np.random.randint(0, num_pix, num_quasars)\n",
    "    rand_pos = val_pos[0][rand]\n",
    "    map_random[rand_pos] = 1\n",
    "\n",
    "    rand_ang = hp.pixelfunc.pix2ang(2**resol_upgrd, rand_pos, lonlat=True)\n",
    "\n",
    "    rand_ra_col = rand_ang[0]\n",
    "    rand_dec_col = rand_ang[1]\n",
    "\n",
    "    rand_red_col = make_rand_from_dist(red_col, num_quasars)\n",
    "    #plt.close()\n",
    "\n",
    "    return rand_ra_col, rand_dec_col, rand_red_col\n",
    "\n",
    "def plot_red_dist(red_col, rand_red_col, bins, draw_ax, den=False):\n",
    "    red_col_shen = red_col\n",
    "    rand_red_col_shen = rand_red_col\n",
    "\n",
    "    hist, edges = np.histogram(red_col_shen, bins=bins)\n",
    "    hist_good, edges_good = np.histogram(red_col_shen_good, bins=bins)\n",
    "\n",
    "    hist_rand, edges_rand = np.histogram(rand_red_col_shen, bins=bins)\n",
    "\n",
    "    #print(edges)\n",
    "    if (den==False):\n",
    "        hist = hist/np.max(hist)\n",
    "        hist_good = hist_good/np.max(hist_good)\n",
    "        hist_rand = hist_rand/np.max(hist_rand)\n",
    "\n",
    "        ax_fin_cl1 = draw_ax\n",
    "        ax_fin_cl1.stairs(hist, edges, label=\"all fields\")\n",
    "        #ax_fin_cl1.stairs(hist_good, edges, label=\"good field only\")\n",
    "        ax_fin_cl1.stairs(hist_rand, edges, label=\"random cat\")\n",
    "        ax_fin_cl1.set_xlabel('z')\n",
    "        ax_fin_cl1.set_ylabel('Distribution')\n",
    "        ax_fin_cl1.legend()\n",
    "    else :\n",
    "        ax_fin_cl1 = draw_ax\n",
    "        ax_fin_cl1.hist(red_col_shen, bins=bins, histtype='step', density=True, label=\"all fields\")\n",
    "        #ax_fin_cl1.stairs(hist_good, edges, label=\"good field only\")\n",
    "        ax_fin_cl1.hist(rand_red_col_shen, bins=bins, histtype='step', density=True, label=\"random cat\")\n",
    "        ax_fin_cl1.set_xlabel('z')\n",
    "        ax_fin_cl1.set_ylabel('Distribution')\n",
    "        ax_fin_cl1.legend()\n",
    "\n",
    "def make_rand_from_dist(red_col, n_samples):            #Make a random z distribution from the data z distribution\n",
    "    bins = [2.90 + i*0.005 for i in range(500)]         #using inverse transform sampling\n",
    "    hist, edges = np.histogram(red_col, bins=bins)\n",
    "    bin_widths = np.diff(edges)\n",
    "    cdf = np.cumsum(hist * bin_widths) / np.sum(hist * bin_widths)\n",
    "    #plt.stairs(cdf, bins)\n",
    "\n",
    "    # Generate new z values that follow the histogram distribution\n",
    "    uniform_values = np.random.rand(n_samples)\n",
    "    bin_indices = np.searchsorted(cdf, uniform_values)\n",
    "    bin_edges = edges[bin_indices-1]\n",
    "    bin_diff = edges[bin_indices] - edges[bin_indices-1]\n",
    "    bin_weights = (uniform_values - cdf[bin_indices-1]) / (cdf[bin_indices] - cdf[bin_indices-1])\n",
    "\n",
    "    new_z_values = bin_edges + bin_weights * bin_diff\n",
    "\n",
    "    ##---------------------------------------------\n",
    "    ## Making changes to see how clustering changes\n",
    "    #new_z_values = np.random.uniform(2.9, 3.5, n_samples)\n",
    "    #new_z_values[300:] = new_z_values[300:] * 1.01\n",
    "    ##\n",
    "\n",
    "    return new_z_values\n",
    "\n",
    "\n",
    "def try_clustering_for_z_dist(rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen):\n",
    "    mpl.rcParams['font.size'] = 18.0\n",
    "    #-------------------------------------------------------------\n",
    "\n",
    "    bins = [2.901 + i*0.05 for i in range(50)]\n",
    "    # fig_fin_cl, (ax_fin_cl1, ax_fin_cl2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "    fig_fin_cl, ax_fin_cl2 = plt.subplots(figsize=(7,7))\n",
    "    # plot_red_dist(red_col_shen, rand_red_col_shen, bins, ax_fin_cl1, den=True)\n",
    "\n",
    "    #-------------------------------------------------------------\n",
    "\n",
    "    s_bins = np.logspace(start=np.log10(1.9868), stop=np.log10(314.915), num=23)\n",
    "    s_mid = (s_bins[:-1] + s_bins[1:])/2\n",
    "\n",
    "    original = ma.masked_values([0, 0, 0, 16.5, 0, 3.54, 1.26, 0.663, 0.191, 0.131, 0.236, -0.280, 0.361, 0.101, 0.0384, 0.0368, 0.0101, 0.0194, -0.00396, 0.0101, -0.00296, 0.00214], 0)\n",
    "    original_error = ma.masked_values([0, 0, 0, 12.8, 0, 3.61, 1.88, 0.733, 0.786, 0.472, 0.175, 0.223, 0.170, 0.121, 0.0862, 0.0644, 0.0382, \\\n",
    "                                       0.0250, 0.0219, 0.0134, 0.00672, 0.00953], 0)\n",
    "\n",
    "    fit_clust = pow(s_mid/ 10.2, -1.71)\n",
    "\n",
    "    ax_fin_cl2.plot(s_mid, fit_clust, '--', label=\"Shen fit\")\n",
    "    ax_fin_cl2.errorbar(s_mid*np.power(10, 0.02), original, original_error, fmt='r*', capsize=5, label=\"Shen data\")\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "\n",
    "    find_xi_s(ra_col_shen, dec_col_shen, red_col_shen, s_bins, \"shen_redshift_space_corr_table_real_signal\",\\\n",
    "                        rand_ra=rand_ra_col_shen, rand_dec=rand_dec_col_shen, rand_red=rand_red_col_shen, draw_ax=ax_fin_cl2)\n",
    "\n",
    "    ax_fin_cl2.legend()\n",
    "\n",
    "### Obtaining the data catalog from table given in Shen et al 2007\n",
    "shen_file_name = DP2_DIRECTORY + \"Data/shen_quasar_sample_datafile1.txt\"\n",
    "shen_data = ascii.read(shen_file_name)\n",
    "sub_flag = shen_data.columns[8]\n",
    "good_flag = shen_data.columns[9]\n",
    "pos = np.where(sub_flag == 1)\n",
    "pos_good = np.where(good_flag == 1)\n",
    "ra_col_shen = shen_data.columns[3][pos].value\n",
    "dec_col_shen = shen_data.columns[4][pos].value\n",
    "red_col_shen = shen_data.columns[5][pos].value\n",
    "\n",
    "ra_col_shen_good = shen_data.columns[3][pos_good].value\n",
    "dec_col_shen_good = shen_data.columns[4][pos_good].value\n",
    "red_col_shen_good = shen_data.columns[5][pos_good].value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to find clustering from Shen quasar sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtaining the Shen quasar sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shen_file_name = DP2_DIRECTORY + \"Data/shen_quasar_sample_datafile1.txt\"\n",
    "shen_data = ascii.read(shen_file_name)\n",
    "sub_flag = shen_data.columns[8]\n",
    "good_flag = shen_data.columns[9]\n",
    "pos = np.where(sub_flag == 1)\n",
    "pos_good = np.where(good_flag == 1)\n",
    "ra_col_shen = shen_data.columns[3][pos].value\n",
    "dec_col_shen = shen_data.columns[4][pos].value\n",
    "red_col_shen = shen_data.columns[5][pos].value\n",
    "\n",
    "ra_col_shen_good = shen_data.columns[3][pos_good].value\n",
    "dec_col_shen_good = shen_data.columns[4][pos_good].value\n",
    "red_col_shen_good = shen_data.columns[5][pos_good].value\n",
    "\n",
    "print(\"There are {} quasars in the catalog\".format(len(ra_col_shen)))\n",
    "ax = plot_sky_map_ps1(ra_col_shen, dec_col_shen, labels=['quasars'], title=\"Shen High redshift quasar catalog\", mark_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [2.9 + i*0.05 for i in range(50)]\n",
    "hist, edges = np.histogram(red_col_shen, bins=bins)\n",
    "hist_good, edges_good = np.histogram(red_col_shen_good, bins=bins)\n",
    "print(edges)\n",
    "hist = hist/np.max(hist)\n",
    "hist_good = hist_good/np.max(hist_good)\n",
    "\n",
    "plt.stairs(hist, edges, label=\"all fields\")\n",
    "plt.stairs(hist_good, edges, label=\"good field only\")\n",
    "plt.title(\"Redshift distribution of Shen quasars\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_col_shen.max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding the footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = []\n",
    "cov_area = []\n",
    "print(\"Level    coverage area\")\n",
    "for i in [3,4,5,6,7,8,9,10]:\n",
    "    map_i, wat = healpix_sky_map_ps1_cover_area(ra_col_shen, dec_col_shen, i, title=\"Level \" + str(i))\n",
    "    level.append(i)\n",
    "    cov_area.append(map_i)\n",
    "    print(f'{i:5d}      {map_i:8.5f}')\n",
    "\n",
    "print(cov_area)\n",
    "fig, ax = plt.subplots(figsize = (12, 7))\n",
    "ax.plot(level, cov_area, '*-')\n",
    "ax.set_title(\"Effective coverage area versus healpix level for Shen complete quasar sample\")\n",
    "ax.set_xlabel(\"Level\")\n",
    "ax.set_ylabel(\"Effective coverage area\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upgrading the footprint finding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 5\n",
    "nside1 = 2**level\n",
    "nside2 = 2**(level + 1)\n",
    "nside3 = 2**(level + 3)\n",
    "nside4 = 2**(level + 4)\n",
    "nside5 = 2**(level + 6)\n",
    "\n",
    "npixels = hp.nside2npix(nside1)\n",
    "hp_map = np.zeros(npixels)\n",
    "\n",
    "ra = ra_col_shen\n",
    "dec = dec_col_shen\n",
    "\n",
    "occ_pix = hp.ang2pix(nside1, ra, dec, lonlat=True)\n",
    "hp_map[occ_pix] = 1\n",
    "hp_map = hp.ud_grade(hp_map, nside2)\n",
    "\n",
    "occ_pix_high = hp.ang2pix(nside2, ra, dec, lonlat=True)\n",
    "hp_map[occ_pix_high] = 0.5\n",
    "hp_map = hp.ud_grade(hp_map, nside3)\n",
    "occ_pix_high = np.where(hp_map == 0.5)\n",
    "\n",
    "\n",
    "occ_pix_high_bound = np.unique(hp.get_all_neighbours(nside3, occ_pix_high))\n",
    "occ_pix_high_bound = np.delete(occ_pix_high_bound, np.where(occ_pix_high_bound == -1))\n",
    "hp_map[occ_pix_high_bound] = 0.5\n",
    "hp_map = hp.ud_grade(hp_map, nside4)\n",
    "occ_pix_high_bound = np.where(hp_map == 0.5)\n",
    "\n",
    "occ_pix_high_bound = np.unique(hp.get_all_neighbours(nside4, occ_pix_high_bound))\n",
    "occ_pix_high_bound = np.delete(occ_pix_high_bound, np.where(occ_pix_high_bound == -1))\n",
    "hp_map[occ_pix_high_bound] = 0.5\n",
    "hp_map = hp.ud_grade(hp_map, nside5)\n",
    "occ_pix_high_bound = np.where(hp_map == 0.5)\n",
    "\n",
    "occ_pix_high_bound = np.unique(hp.get_all_neighbours(nside5, occ_pix_high_bound))\n",
    "occ_pix_high_bound = np.delete(occ_pix_high_bound, np.where(occ_pix_high_bound == -1))\n",
    "hp_map[occ_pix_high_bound] = 0.5\n",
    "\n",
    "# temp_ra, temp_dec = hp.pix2ang(nside3, occ_pix_high_bound, lonlat=True)\n",
    "# print(np.where(occ_pix_high_bound == -1))\n",
    "# occ_pix_high_bound_extra = np.unique(hp.get_all_neighbours(nside3, temp_theta[1:], temp_phi[1:]))\n",
    "\n",
    "# hp_map = hp.ud_grade(hp_map, nside3)\n",
    "\n",
    "\n",
    "# hp_map[occ_pix_high_bound_extra] = 0.5\n",
    "\n",
    "pixels_with_data = np.shape(np.where(hp_map == 0.5))[1]\n",
    "area_data_pixels = pixels_with_data * hp.nside2pixarea(hp.get_nside(hp_map), degrees=True)\n",
    "print(area_data_pixels)\n",
    "\n",
    "hp.mollview(hp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_map_up = np.zeros(hp.nside2npix(hp.get_nside(hp_map)))\n",
    "hp_map_up[np.where(hp_map == 0.5)] = 1\n",
    "\n",
    "# nside_big = 2 ** 14\n",
    "# hp_map_up = hp.ud_grade(hp_map_up, nside_big)\n",
    "\n",
    "hp.mollview(hp_map_up, title=\"Best approximation of PS1 footprint\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clustering measurement for the upgraded footprint----- BEST ONE YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v3(ra_col_shen, dec_col_shen, red_col_shen, 5, 20)\n",
    "\n",
    "try_clustering_for_z_dist(rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v3(ra_col_shen, dec_col_shen, red_col_shen, 5, 1)\n",
    "plot_sky_map_ps1(rand_ra_col_shen, rand_dec_col_shen, ['quasars'], title=\"Random catalog made for shen quasar sample\", mark_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.05\n",
    "bins = [2.901 + i*0.05 for i in range(50)]\n",
    "\n",
    "with plt.style.context('bmh'):\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    # hist, bins = np.histogram(red_col_schind_23, bins)\n",
    "    # hist = hist/np.max(hist)\n",
    "    ax.hist(red_col_shen, bins, density=True, histtype='step', zorder=10, alpha=1, label = 'Shen sample')\n",
    "    ax.grid(zorder=1, alpha=0.3)\n",
    "    ax.set_xlabel('redshift')\n",
    "    ax.set_ylabel('number density')\n",
    "    ax.set_aspect('auto')\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "    ax.hist(rand_red_col_shen, bins, density=True, histtype='step', zorder=10, alpha =1, label = 'random sample')\n",
    "    ax.grid(zorder=1, alpha=0.3)\n",
    "    ax.set_xlabel('redshift')\n",
    "    ax.set_ylabel('normalized number count')\n",
    "    ax.set_aspect('auto')\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot: distribution of random catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sky_map_ps1_v2(ra, dec, mask = None, title='', labels=['quasars'], mark_size=30):\n",
    "\n",
    "    if (mask == None):\n",
    "        mask = np.zeros_like(ra, dtype='int')\n",
    "        mask = np.insert(mask, 0, 1)\n",
    "\n",
    "    ### Plots the lines marking the excluded area of the galactic plane\n",
    "    res = 511\n",
    "    gal_l = np.linspace(0, 360, res)\n",
    "    gal_b = np.ones(res) * 20.0\n",
    "    gal_line_1 = SkyCoord(gal_l, gal_b, frame = 'galactic', unit = 'deg')\n",
    "    gal_line_2 = SkyCoord(gal_l, -gal_b, frame = 'galactic', unit = 'deg')\n",
    "    ### gal_line_equat is the galactic line in equatorial coordinates\n",
    "    gal_line_equat_1 = gal_line_1.transform_to('icrs')   \n",
    "    gal_line_equat_2 = gal_line_2.transform_to('icrs')\n",
    "    gal_ra_1 = np.radians(range_wrapper(gal_line_equat_1.ra.degree))\n",
    "    ###Sorting the array in order to do line plot\n",
    "    i_sorted = np.argsort(gal_ra_1) \n",
    "    gal_ra_1 = gal_ra_1[i_sorted]\n",
    "    gal_dec_1 = np.radians(gal_line_equat_1.dec.degree)[i_sorted]\n",
    "    gal_ra_2 = np.radians(range_wrapper(gal_line_equat_2.ra.degree))\n",
    "    i_sorted = np.argsort(gal_ra_2)\n",
    "    gal_ra_2 = gal_ra_2[i_sorted]\n",
    "    gal_dec_2 = np.radians(gal_line_equat_2.dec.degree)[i_sorted]\n",
    "    ### dec -30 array is obtained\n",
    "    dec_30_ra = np.radians(range_wrapper(np.linspace(0, 360, res)))\n",
    "    dec_30_dec = np.radians(np.ones(res) * -30.0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12, 7), subplot_kw={'projection': 'mollweide'})\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    plt.rc('legend', fontsize=14)\n",
    "    #ax = plt.subplot(111, projection = \"mollweide\")\n",
    "\n",
    "    ### This plots the footprint\n",
    "    ax.plot(gal_ra_1, gal_dec_1, color = 'black', linestyle='--', linewidth = 1) \n",
    "    ax.plot(gal_ra_2, gal_dec_2, color = 'black', linestyle='--', linewidth = 1)\n",
    "    # ax.plot(dec_30_ra, dec_30_dec, color = 'black', linestyle='-.', linewidth = 1)\n",
    "    #-------------------------------------------------------------------------------------------\n",
    "    ### Plotting the sources\n",
    "    ra = np.radians(range_wrapper(ra)) \n",
    "    dec = np.radians(dec)\n",
    "    marker = ['o','x']\n",
    "\n",
    "    for n_source in range(mask[0]):\n",
    "        source_pos = np.where(mask[1:] == n_source)\n",
    "        ra_n, dec_n = ra[source_pos], dec[source_pos]\n",
    "\n",
    "        ax.scatter(ra_n, dec_n, marker = marker[n_source], label = labels[n_source], color='navy', alpha=1, s = mark_size, zorder=10)\n",
    "\n",
    "    # foot_ra, foot_dec, foot_red = make_shen_random_catalog_v3(ra_col_shen, dec_col_shen, red_col_shen, 5, 50)\n",
    "    # foot_ra=np.radians(range_wrapper(foot_ra))\n",
    "    # foot_dec = np.radians(foot_dec)\n",
    "    # ax.scatter(foot_ra, foot_dec, color='grey', s=0.1, zorder=2, alpha = 0.05)  \n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_xticklabels([\"10h\", \"8h\", \"6h\", \"4h\", \"2h\", \"0h\", \"22h\", \"20h\", \"18h\", \"16h\", \"14h\"]);\n",
    "    #plt.style.use(astropy_mpl_style)\n",
    "\n",
    "    return ax\n",
    "\n",
    "ax = plot_sky_map_ps1_v2(ra_col_shen, dec_col_shen,labels = ['quasars'], title=\"\", mark_size=0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing our DD pair counts agrees with that of Shen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bins = np.logspace(start=np.log10(1.9868), stop=np.log10(314.915), num=23)\n",
    "s_mid = (s_bins[:-1] + s_bins[1:])/2\n",
    "\n",
    "s_array = find_s_bined(ra_col_shen, dec_col_shen, red_col_shen)\n",
    "\n",
    "s_hist, edges = np.histogram(s_array, s_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shen_DD_original = np.array([0.0, 0.0, 0.0, 1.8, 0.0, 1.8, 1.8, 2.7, 4.5, 8.9, 15.2, 22.4, 70.7, 104.9, 210.9, 384.8, 734.2, 1417.1, 2565.8, 4821.6, 8631.8, 15365.1])\n",
    "shen_RR_original = np.array([0.9, 5.4, 6.3, 14.4, 34.2, 38.7, 99.0, 215.0, 406.5, 804.2, 1592.4,\\\n",
    "                              3123.6, 6028.6, 11959.1, 23480.2, 45648.7, 88337.9, 168480.9, 3117727.8, 588892.8, 1070807.1, 1912774.1])\n",
    "plt.stairs(s_hist, s_bins)\n",
    "plt.stairs(shen_DD_original, s_bins)\n",
    "plt.xlabel('s')\n",
    "plt.ylabel('DD')\n",
    "\n",
    "print((s_hist - shen_DD_original)/s_hist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to make a random catalog for Shen quasars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random catalog examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog(ra_col_shen, dec_col_shen, red_col_shen, 5, 11, 2)\n",
    "plt.close()\n",
    "\n",
    "plot_sky_map_ps1(rand_ra_col_shen, rand_dec_col_shen, labels=['quasars'], title=\"Random catalog made for Shen quasar sample\", mark_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random catalog making v2\n",
    "\n",
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v2(ra_col_shen, dec_col_shen, red_col_shen, 5, 1)\n",
    "plt.close()\n",
    "\n",
    "plot_sky_map_ps1(rand_ra_col_shen, rand_dec_col_shen, labels=['quasars'], title=\"Random catalog made for Shen quasar sample\", mark_size=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redshift distribution of the random catalog from inverse tranform sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog(ra_col_shen, dec_col_shen, red_col_shen, 5, 11, 2)\n",
    "plt.close()\n",
    "\n",
    "bins = [2.901 + i*0.05 for i in range(50)]\n",
    "hist, edges = np.histogram(red_col_shen, bins=bins)\n",
    "hist_good, edges_good = np.histogram(red_col_shen_good, bins=bins)\n",
    "\n",
    "hist_rand, edges_rand = np.histogram(rand_red_col_shen, bins=bins)\n",
    "\n",
    "#print(edges)\n",
    "hist = hist/np.max(hist)\n",
    "hist_good = hist_good/np.max(hist_good)\n",
    "hist_rand = hist_rand/np.max(hist_rand)\n",
    "\n",
    "plt.stairs(hist, edges, label=\"all fields\")\n",
    "#plt.stairs(hist_good, edges, label=\"good field only\")\n",
    "plt.stairs(hist_rand, edges, label=\"random cat\")\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('Distribution')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing the random catalog made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### converting the random catalog to a bunch of x, y and z in comoving coordinates\n",
    "\n",
    "rand_ra_col, rand_dec_col, rand_red_col = make_shen_random_catalog_v2(ra_col_shen, dec_col_shen, red_col_shen, 5, 12)\n",
    "plt.close()\n",
    "\n",
    "s_bins = np.logspace(start=np.log10(1.9868), stop=np.log10(314.915), num=23)\n",
    "\n",
    "s_hist = (pair_count_corrfunc(ra_col_shen, dec_col_shen, red_col_shen, s_bins)[:,3]).astype(int)\n",
    "rand_s_hist = (pair_count_corrfunc(rand_ra_col, rand_dec_col, rand_red_col, s_bins)[:,3]).astype(int)\n",
    "cross_s_hist = (pair_count_corrfunc(ra_col_shen, dec_col_shen, red_col_shen, s_bins, rand_ra_col=rand_ra_col, rand_dec_col=rand_dec_col, rand_red_col=rand_red_col)[:,3]).astype(int) * 2\n",
    "s_hist_norm = (len(ra_col_shen) * (len(ra_col_shen) - 1))/2\n",
    "rand_hist_norm = (len(rand_ra_col) * (len(rand_ra_col) - 1))/2\n",
    "cross_hist_norm = len(ra_col_shen) * len(rand_ra_col)\n",
    "\n",
    "unfin_pos = np.where(s_hist * rand_s_hist * cross_s_hist == 0)\n",
    "\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    xi_s = (s_hist/s_hist_norm - 2 * cross_s_hist/cross_hist_norm + rand_s_hist/rand_hist_norm)/(rand_s_hist/rand_hist_norm)\n",
    "xi_s_masked = ma.array(xi_s)\n",
    "xi_s_masked[unfin_pos] = -999\n",
    "\n",
    "printer = np.array([s_hist, rand_s_hist, cross_s_hist, xi_s_masked]).T\n",
    "print(printer)\n",
    "print(rand_hist_norm/s_hist_norm)\n",
    "\n",
    "# binned_rand = find_s_bined(rand_ra_col, rand_dec_col, rand_red_col)\n",
    "# hist_rand = np.histogram(binned_rand, s_bins)\n",
    "# print(hist_rand[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best attempt on cluster measurement so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog(ra_col_shen, dec_col_shen, red_col_shen, 5, 11, 1)\n",
    "# plt.close()\n",
    "\n",
    "def make_rand_from_dist(red_col, n_samples):            #Make a random z distribution from the data z distribution\n",
    "    bins = [2.90 + i*0.005 for i in range(500)]         #using inverse transform sampling\n",
    "    hist, edges = np.histogram(red_col, bins=bins)\n",
    "    print(np.shape(hist))\n",
    "    bin_widths = np.diff(edges)\n",
    "    cdf = np.cumsum(hist * bin_widths) / np.sum(hist * bin_widths)\n",
    "    cdf = np.insert(cdf, 0, 0)\n",
    "    #plt.stairs(cdf, bins)\n",
    "\n",
    "    # Generate new z values that follow the histogram distribution\n",
    "    uniform_values = np.random.rand(n_samples)\n",
    "    bin_indices = np.searchsorted(cdf, uniform_values)\n",
    "    bin_edges = edges[bin_indices-1]\n",
    "    bin_diff = edges[bin_indices] - edges[bin_indices-1]\n",
    "    bin_weights = (uniform_values - cdf[bin_indices-1]) / (cdf[bin_indices] - cdf[bin_indices-1])\n",
    "\n",
    "    new_z_values = bin_edges + bin_weights * bin_diff\n",
    "\n",
    "    ##---------------------------------------------\n",
    "    ## Making changes to see how clustering changes\n",
    "    #new_z_values = np.random.uniform(2.9, 3.5, n_samples)\n",
    "    #new_z_values[300:] = new_z_values[300:] * 1.01\n",
    "    ##\n",
    "\n",
    "    return new_z_values\n",
    "\n",
    "### Trying the clustering with the v2 of random catalog maker\n",
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v2(ra_col_shen, dec_col_shen, red_col_shen, 5, 10)\n",
    "plt.close()\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "bins = [2.901 + i*0.05 for i in range(50)]\n",
    "fig_fin_cl, (ax_fin_cl1, ax_fin_cl2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "plot_red_dist(red_col_shen, rand_red_col_shen, bins, ax_fin_cl1)\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "s_bins = np.logspace(start=np.log10(1.9868), stop=np.log10(314.915), num=23)\n",
    "s_mid = (s_bins[:-1] + s_bins[1:])/2\n",
    "\n",
    "original = ma.masked_values([0, 0, 0, 16.5, 0, 3.54, 1.26, 0.663, 0.191, 0.131, 0.236, 0, 0.361, 0.101, 0.0384, 0.0368, 0.0101, 0.0194, 0, 0.0101, 0, 0.00214], 0)\n",
    "\n",
    "fit_clust = pow(s_mid/ 10.2, -1.71)\n",
    "\n",
    "ax_fin_cl2.plot(s_mid, fit_clust, '--', label=\"Shen fit\")\n",
    "ax_fin_cl2.plot(s_mid, original, 'r*', label=\"Shen data\")\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "find_xi_s(ra_col_shen, dec_col_shen, red_col_shen, s_bins, \"shen_redshift_space_corr_table_real_signal\",\\\n",
    "                     rand_ra=rand_ra_col_shen, rand_dec=rand_dec_col_shen, rand_red=rand_red_col_shen, draw_ax=ax_fin_cl2)\n",
    "\n",
    "ax_fin_cl2.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to find the probability, $P(z)$ of quasars from selection function $S(z)$ and the redshift evolution of density due to expansion of universe $\\rho(z) = \\rho(0)(1+z)^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_sel_fun_file_name = DP2_DIRECTORY + 'Data/sdss_q_sel_fun_richards.dat'\n",
    "sdss_sel_fun_file = open(sdss_sel_fun_file_name, 'r')\n",
    "sdss_sel_fun = np.genfromtxt(sdss_sel_fun_file)\n",
    "\n",
    "sel_fun_imag_col = sdss_sel_fun[:,0]\n",
    "sel_fun_z_col = sdss_sel_fun[:,1]\n",
    "sel_fun_point_col = sdss_sel_fun[:,2]\n",
    "sel_fun_radio_col = sdss_sel_fun[:,3]\n",
    "sel_fun_extended_col = sdss_sel_fun[:,4]\n",
    "\n",
    "### selection function is given in the following way: 53 i magnitudes are there from 15.0 to 20.2, difference of 0.1, for each magnitude 121 z values \n",
    "# from 0.0 to 6.0 is given with difference of 0.05.\n",
    "\n",
    "sel_fun_z = sel_fun_z_col[0:121] ### this is the z values where we have the S(z)\n",
    "sel_fun_imag = np.reshape(sel_fun_imag_col, (53,121))[:,0]\n",
    "sel_fun_point_val = np.sum(np.reshape(sel_fun_point_col,(53, 121)), axis=0) * 0.1\n",
    "sel_fun_point_grid = np.reshape(sel_fun_point_col,(53, 121))\n",
    "sel_fun_radio_val = np.sum(np.reshape(sel_fun_radio_col,(53, 121)), axis=0) * 0.1\n",
    "sel_fun_ext_val = np.sum(np.reshape(sel_fun_extended_col,(53, 121)), axis=0) * 0.1\n",
    "\n",
    "loc_29_54 = np.where((sel_fun_z >= 2.9) & (sel_fun_z <= 5.4))\n",
    "sel_fun_z_act= sel_fun_z[loc_29_54][1:-1]\n",
    "sel_fun_z_bins = (sel_fun_z[loc_29_54] - 0.05/2)[1:]\n",
    "sel_fun_point_act = (sel_fun_point_val[loc_29_54])[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.power(1 + sel_fun_z_act, 3) * sel_fun_point_act\n",
    "denominator = np.sum(numerator) * 0.1\n",
    "pz = numerator/denominator\n",
    "numerator.shape\n",
    "\n",
    "fig1, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,10)) #, sharex=True, sharey=True)\n",
    "ax1.plot(sel_fun_z_act, sel_fun_point_act)\n",
    "ax1.set_title('selection function')\n",
    "ax2.plot(sel_fun_z_act, np.power(1+sel_fun_z_act, 3))\n",
    "ax2.set_title(r'$(1 + z)^3$')\n",
    "ax3.plot(sel_fun_z_act, numerator)\n",
    "ax3.set_title('unnormalised P(z)')\n",
    "ax4.plot(sel_fun_z_act, pz)\n",
    "ax4.set_title('normalised P(z)')\n",
    "ax3.set_xlabel('z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rand_from_pz(pz, bins, n_samples):\n",
    "    hist, edges = pz, bins\n",
    "    bin_widths = np.diff(edges)\n",
    "    cdf = np.cumsum(hist * bin_widths) / np.sum(hist * bin_widths)\n",
    "    #plt.stairs(cdf, bins)\n",
    "\n",
    "    # Generate new z values that follow the histogram distribution\n",
    "    uniform_values = np.random.rand(n_samples)\n",
    "    bin_indices = np.searchsorted(cdf, uniform_values)\n",
    "    bin_edges = edges[bin_indices-1]\n",
    "    bin_diff = edges[bin_indices] - edges[bin_indices-1]\n",
    "    bin_weights = (uniform_values - cdf[bin_indices-1]) / (cdf[bin_indices] - cdf[bin_indices-1])\n",
    "\n",
    "    new_z_values = bin_edges + bin_weights * bin_diff\n",
    "\n",
    "    return new_z_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v2(ra_col_shen, dec_col_shen, red_col_shen, 5, 10)\n",
    "plt.close()\n",
    "rand_red_col_shen = make_rand_from_pz(pz, sel_fun_z_bins, len(rand_ra_col_shen))\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "bins = [2.901 + i*0.05 for i in range(50)]\n",
    "fig_fin_cl, (ax_fin_cl1, ax_fin_cl2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "plot_red_dist(red_col_shen, rand_red_col_shen, bins, ax_fin_cl1)\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "s_bins = np.logspace(start=np.log10(1.9868), stop=np.log10(314.915), num=23)\n",
    "s_mid = (s_bins[:-1] + s_bins[1:])/2\n",
    "\n",
    "original = ma.masked_values([0, 0, 0, 16.5, 0, 3.54, 1.26, 0.663, 0.191, 0.131, 0.236, 0, 0.361, 0.101, 0.0384, 0.0368, 0.0101, 0.0194, 0, 0.0101, 0, 0.00214], 0)\n",
    "\n",
    "fit_clust = pow(s_mid/ 10.2, -1.71)\n",
    "\n",
    "ax_fin_cl2.plot(s_mid, fit_clust, '--', label=\"Shen fit\")\n",
    "ax_fin_cl2.plot(s_mid, original, 'r*', label=\"Shen data\")\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "find_xi_s(ra_col_shen, dec_col_shen, red_col_shen, s_bins, \"shen_redshift_space_corr_table_real_signal\",\\\n",
    "                     rand_ra=rand_ra_col_shen, rand_dec=rand_dec_col_shen, rand_red=rand_red_col_shen, draw_ax=ax_fin_cl2)\n",
    "\n",
    "ax_fin_cl2.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial and error to see how the clustering measure differs with redshift distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rand_from_dist(red_col, n_samples):            #Make a random z distribution from the data z distribution\n",
    "    bins = [2.90 + i*0.0005 for i in range(5000)]         #using inverse transform sampling\n",
    "    hist, edges = np.histogram(red_col, bins=bins)\n",
    "    \n",
    "    print(hist)\n",
    "    #hist[np.where(hist < 5)] = hist[np.where(hist < 5)] - 0\n",
    "\n",
    "    bin_widths = np.diff(edges)\n",
    "    cdf = np.cumsum(hist * bin_widths) / np.sum(hist * bin_widths)\n",
    "    #plt.stairs(cdf, bins)\n",
    "\n",
    "    # Generate new z values that follow the histogram distribution\n",
    "    uniform_values = np.random.rand(n_samples)\n",
    "    bin_indices = np.searchsorted(cdf, uniform_values)\n",
    "    bin_edges = edges[bin_indices-1]\n",
    "    bin_diff = edges[bin_indices] - edges[bin_indices-1]\n",
    "    bin_weights = (uniform_values - cdf[bin_indices-1]) / (cdf[bin_indices] - cdf[bin_indices-1])\n",
    "\n",
    "    new_z_values = bin_edges + bin_weights * bin_diff\n",
    "\n",
    "    ##---------------------------------------------\n",
    "    ## Making changes to see how clustering changes\n",
    "    #new_z_values = np.random.uniform(2.9, 3.5, n_samples)\n",
    "    #new_z_values[300:] = new_z_values[300:] * 1.01\n",
    "    ##\n",
    "\n",
    "    return new_z_values\n",
    "\n",
    "### Trying the clustering with the v2 of random catalog maker\n",
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v2(ra_col_shen, dec_col_shen, red_col_shen, 5, 10)\n",
    "plt.close()\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "bins = [2.901 + i*0.05 for i in range(50)]\n",
    "fig_fin_cl, (ax_fin_cl1, ax_fin_cl2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "# plot_red_dist(red_col_shen, rand_red_col_shen, bins, ax_fin_cl1)\n",
    "ax_fin_cl1.hist(red_col_shen, bins, histtype='step', density=True)\n",
    "ax_fin_cl1.hist(rand_red_col_shen, bins, histtype='step', density=True)\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "s_bins = np.logspace(start=np.log10(1.9868), stop=np.log10(314.915), num=23)\n",
    "s_mid = (s_bins[:-1] + s_bins[1:])/2\n",
    "\n",
    "original = ma.masked_values([0, 0, 0, 16.5, 0, 3.54, 1.26, 0.663, 0.191, 0.131, 0.236, 0, 0.361, 0.101, 0.0384, 0.0368, 0.0101, 0.0194, 0, 0.0101, 0, 0.00214], 0)\n",
    "\n",
    "fit_clust = pow(s_mid/ 10.2, -1.71)\n",
    "\n",
    "ax_fin_cl2.plot(s_mid, fit_clust, '--', label=\"Shen fit\")\n",
    "ax_fin_cl2.plot(s_mid, original, 'r*', label=\"Shen data\")\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "find_xi_s(ra_col_shen, dec_col_shen, red_col_shen, s_bins, \"shen_redshift_space_corr_table_real_signal\",\\\n",
    "                     rand_ra=rand_ra_col_shen, rand_dec=rand_dec_col_shen, rand_red=rand_red_col_shen, draw_ax=ax_fin_cl2)\n",
    "\n",
    "ax_fin_cl2.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with the quasar selection function as given in Richards et al 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_sel_fun_file_name = DP2_DIRECTORY + 'Data/sdss_q_sel_fun_richards.dat'\n",
    "sdss_sel_fun_file = open(sdss_sel_fun_file_name, 'r')\n",
    "sdss_sel_fun = np.genfromtxt(sdss_sel_fun_file)\n",
    "\n",
    "sel_fun_imag_col = sdss_sel_fun[:,0]\n",
    "sel_fun_z_col = sdss_sel_fun[:,1]\n",
    "sel_fun_point_col = sdss_sel_fun[:,2]\n",
    "sel_fun_radio_col = sdss_sel_fun[:,3]\n",
    "sel_fun_extended_col = sdss_sel_fun[:,4]\n",
    "\n",
    "### selection function is given in the following way: 53 i magnitudes are there from 15.0 to 20.2, difference of 0.1, for each magnitude 121 z values \n",
    "# from 0.0 to 6.0 is given with difference of 0.05.\n",
    "\n",
    "sel_fun_z = sel_fun_z_col[0:121]\n",
    "sel_fun_imag = np.reshape(sel_fun_imag_col, (53,121))[:,0]\n",
    "sel_fun_point_val = np.sum(np.reshape(sel_fun_point_col,(53, 121)), axis=0) * 0.1\n",
    "sel_fun_point_grid = np.reshape(sel_fun_point_col,(53, 121))\n",
    "sel_fun_radio_val = np.sum(np.reshape(sel_fun_radio_col,(53, 121)), axis=0) * 0.1\n",
    "sel_fun_ext_val = np.sum(np.reshape(sel_fun_extended_col,(53, 121)), axis=0) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,10), sharex=True, sharey=True)\n",
    "ax1.plot(sel_fun_z, sel_fun_point_val)\n",
    "ax1.set_title('point')\n",
    "ax2.plot(sel_fun_z, sel_fun_radio_val)\n",
    "ax2.set_title('radio')\n",
    "ax3.plot(sel_fun_z, sel_fun_ext_val)\n",
    "ax3.set_title('extended')\n",
    "ax4.plot(sel_fun_z, (sel_fun_point_val + sel_fun_radio_val + sel_fun_ext_val)/3)\n",
    "ax4.set_title('average of all')\n",
    "ax3.set_xlabel('z')\n",
    "ax1.set_ylabel('fraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_z = (sel_fun_z >= 2.9) & (sel_fun_z <= 5.4)\n",
    "sel_fun_point_grid_real = sel_fun_point_grid[:,loc_z].T\n",
    "sel_fun_z_real = sel_fun_z[loc_z]\n",
    "\n",
    "im_sel = plt.imshow(sel_fun_point_grid_real.T, extent=[sel_fun_z_real.min(), sel_fun_z_real.max(), sel_fun_imag.max(), sel_fun_imag.min()], aspect='auto', vmin=0)\n",
    "plt.colorbar(im_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_fun_point_grid_real.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### QLF from Richards et al 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import LambdaCDM as LCDM\n",
    "cosmo = LCDM(H0=70, Om0=0.3, Ode0=0.7)  ## they could have calculated luminosity distance differently\n",
    "d_z2 = cosmo.luminosity_distance(z=2)\n",
    "\n",
    "def QLF_phi_app(m, z, **kwargs):\n",
    "    M_z2 = m - 5 * np.log10(cosmo.luminosity_distance(z=4)/(1E-5 * u.Mpc))\n",
    "    phi_ast = pow(10, kwargs['log_phi_ast'])\n",
    "    zeta = np.log10((1+z)/(1+kwargs['z_ref']))\n",
    "    mu = M_z2 - (kwargs['M_ast'] + kwargs['B1']*zeta + kwargs['B2']*pow(zeta,2) + kwargs['B3']*pow(zeta,3))\n",
    "    phi = phi_ast * pow(10, mu* (kwargs['A1'] + kwargs['A2'] * (z - 2.45)))\n",
    "\n",
    "    return phi\n",
    "\n",
    "def QLF_phi_abs(M, z, **kwargs):\n",
    "    phi_ast = pow(10, kwargs['log_phi_ast'])\n",
    "    zeta = np.log10((1+z)/(1+kwargs['z_ref']))\n",
    "    mu = M - (kwargs['M_ast'] + kwargs['B1']*zeta + kwargs['B2']*pow(zeta,2) + kwargs['B3']*pow(zeta,3))\n",
    "    phi = phi_ast * pow(10, mu* (kwargs['A1'] + kwargs['A2'] * (z - 2.45)))\n",
    "\n",
    "    return phi   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {'A1':0.83, 'A2':-0.11, 'B1':1.43, 'B2':36.63, 'B3':34.39, 'M_ast':-26, 'z_ref':2.45, 'log_phi_ast':-5.70}\n",
    "\n",
    "z_array = np.linspace(0, 5, 100)\n",
    "phi_array = QLF_phi_app(15, z_array, **keywords)\n",
    "\n",
    "plt.plot(z_array, phi_array)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_array = sel_fun_imag\n",
    "z_array = sel_fun_z[(sel_fun_z >= 2.9) & (sel_fun_z <= 5.4)]\n",
    "m_grid, z_grid = np.meshgrid(m_array, z_array)\n",
    "phi_array1 = QLF_phi_app(m_grid, z_grid, **keywords)\n",
    "\n",
    "im = plt.imshow(phi_array1, extent=[z_array.min(), z_array.max(), m_array.min(), m_array.max()], norm='log', aspect='auto')\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_array = np.linspace(-15.0, -20.2, 100)\n",
    "z_array = np.linspace(2.9, 5.4, 1000)\n",
    "\n",
    "M_grid, z_grid = np.meshgrid(m_array, z_array)\n",
    "phi_array2 = QLF_phi_abs(M_grid, z_grid, **keywords)\n",
    "\n",
    "im1 = plt.imshow(phi_array2, extent=[z_array.min(), z_array.max(), M_array.min(), M_array.max()], norm='log', aspect='auto')\n",
    "plt.colorbar(im1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a new random catalog via the QLF with each magnitude bin considered seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import LambdaCDM as LCDM\n",
    "cosmo = LCDM(H0=70, Om0=0.3, Ode0=0.7)  ## they could have calculated luminosity distance differently\n",
    "d_z2 = cosmo.luminosity_distance(z=2)\n",
    "\n",
    "def QLF_phi_app(m, z, **kwargs):\n",
    "    M_z2 = m - 5 * np.log10(cosmo.luminosity_distance(z=4)/(1E-5 * u.Mpc))\n",
    "    phi_ast = pow(10, kwargs['log_phi_ast'])\n",
    "    zeta = np.log10((1+z)/(1+kwargs['z_ref']))\n",
    "    mu = M_z2 - (kwargs['M_ast'] + kwargs['B1']*zeta + kwargs['B2']*pow(zeta,2) + kwargs['B3']*pow(zeta,3))\n",
    "    phi = phi_ast * pow(10, mu* (kwargs['A1'] + kwargs['A2'] * (z - 2.45)))\n",
    "\n",
    "    return phi.value\n",
    "\n",
    "keywords = {'A1':0.83, 'A2':-0.11, 'B1':1.43, 'B2':36.63, 'B3':34.39, 'M_ast':-26, 'z_ref':2.45, 'log_phi_ast':-5.70}\n",
    "\n",
    "sdss_sel_fun_file_name = DP2_DIRECTORY + 'Data/sdss_q_sel_fun_richards.dat'\n",
    "sdss_sel_fun_file = open(sdss_sel_fun_file_name, 'r')\n",
    "sdss_sel_fun = np.genfromtxt(sdss_sel_fun_file)\n",
    "\n",
    "sel_fun_imag_col = sdss_sel_fun[:,0]\n",
    "sel_fun_z_col = sdss_sel_fun[:,1]\n",
    "sel_fun_point_col = sdss_sel_fun[:,2]\n",
    "sel_fun_radio_col = sdss_sel_fun[:,3]\n",
    "sel_fun_extended_col = sdss_sel_fun[:,4]\n",
    "\n",
    "### selection function is given in the following way: 53 i magnitudes are there from 15.0 to 20.2, difference of 0.1, for each magnitude 121 z values \n",
    "# from 0.0 to 6.0 is given with difference of 0.05.\n",
    "\n",
    "sel_fun_z = sel_fun_z_col[0:121] ### this is the z values where we have the S(z)\n",
    "sel_fun_imag = np.reshape(sel_fun_imag_col, (53,121))[:,0]\n",
    "sel_fun_point_val = np.sum(np.reshape(sel_fun_point_col,(53, 121)), axis=0) * 0.1\n",
    "sel_fun_point_grid = np.reshape(sel_fun_point_col,(53, 121))\n",
    "sel_fun_radio_val = np.sum(np.reshape(sel_fun_radio_col,(53, 121)), axis=0) * 0.1\n",
    "sel_fun_ext_val = np.sum(np.reshape(sel_fun_extended_col,(53, 121)), axis=0) * 0.1\n",
    "\n",
    "loc_29_54 = np.where((sel_fun_z >= 2.9) & (sel_fun_z <= 5.05))\n",
    "sel_fun_z_act= sel_fun_z[loc_29_54][1:-1]\n",
    "sel_fun_z_bins = (sel_fun_z[loc_29_54] - 0.05/2)[1:]\n",
    "sel_fun_point_act = (sel_fun_point_val[loc_29_54])[1:-1]\n",
    "\n",
    "def make_rand_from_pz(pz, bins, n_samples):\n",
    "    hist, edges = pz, bins\n",
    "    bin_widths = np.diff(edges)\n",
    "    cdf = np.cumsum(hist * bin_widths) / np.sum(hist * bin_widths)\n",
    "    #plt.stairs(cdf, bins)\n",
    "\n",
    "    # Generate new z values that follow the histogram distribution\n",
    "    uniform_values = np.random.rand(n_samples)\n",
    "    bin_indices = np.searchsorted(cdf, uniform_values)\n",
    "    bin_edges = edges[bin_indices-1]\n",
    "    bin_diff = edges[bin_indices] - edges[bin_indices-1]\n",
    "    bin_weights = (uniform_values - cdf[bin_indices-1]) / (cdf[bin_indices] - cdf[bin_indices-1])\n",
    "\n",
    "    new_z_values = bin_edges + bin_weights * bin_diff\n",
    "\n",
    "    return new_z_values\n",
    "\n",
    "def make_rand_from_n_m_z(n_mz, z_bins, n_samples):\n",
    "    n_mz[np.where(n_mz < 0)] = 0\n",
    "    n_mz = n_mz/(np.sum(np.sum(n_mz, axis=0) * 0.1, axis=0) * 0.05)\n",
    "    z_samples = np.array([])\n",
    "    for i in range(len(n_mz)-1):\n",
    "        temp_samp = int(np.sum(n_mz[i]) * 0.05 * 0.1 * n_samples + 1)\n",
    "        temp_pz = n_mz[i]/(np.sum(n_mz[i]) * 0.05)\n",
    "        z_samples = np.concatenate((z_samples, make_rand_from_pz(temp_pz, z_bins, temp_samp)))\n",
    "\n",
    "    np.random.shuffle(z_samples)\n",
    "    return z_samples[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_values, z_values = np.meshgrid(sel_fun_imag, sel_fun_z)\n",
    "m_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_array = QLF_phi_app(m_values, z_values, **keywords)\n",
    "phi_array = np.sum(phi_array, axis=1) * (sel_fun_imag[1] - sel_fun_imag[0])\n",
    "plt.plot(sel_fun_z, phi_array)\n",
    "plt.yscale('log')\n",
    "plt.ylim((1E-9, 1E-7))\n",
    "plt.xlim((2.9, 5.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.where((sel_fun_z_col >= 2.95) & (sel_fun_z_col <= 5.35))\n",
    "sel_fun_array = sel_fun_point_col[loc]\n",
    "sel_fun_array = sel_fun_array.reshape(53, 49)\n",
    "\n",
    "zarr, magarr = np.meshgrid(sel_fun_z_act, sel_fun_imag)\n",
    "\n",
    "qlf_array = QLF_phi_app(magarr, zarr, **keywords)\n",
    "\n",
    "n_arr = sel_fun_array * qlf_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.sum(n_arr, axis=0) * 0.1\n",
    "denom = np.sum(num) * 0.05\n",
    "n_z = num/denom\n",
    "plt.plot(sel_fun_z_act, n_z)\n",
    "\n",
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v3(ra_col_shen, dec_col_shen, red_col_shen, 5, 10)\n",
    "plt.close()\n",
    "rand_red_col_shen = make_rand_from_pz(n_z, sel_fun_z_bins, len(rand_ra_col_shen))\n",
    "\n",
    "try_clustering_for_z_dist(rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.where((sel_fun_z_col >= 2.95) & (sel_fun_z_col <= 5.00))\n",
    "sel_fun_z_act = sel_fun_z[np.where((sel_fun_z >= 2.95) & (sel_fun_z <= 5.00))]\n",
    "z_len = len(sel_fun_z_act)\n",
    "sel_fun_array = sel_fun_point_col[loc]\n",
    "sel_fun_array = sel_fun_array.reshape(53, z_len)\n",
    "\n",
    "loc_29_54 = np.where((sel_fun_z >= 2.9) & (sel_fun_z <= 5.05))\n",
    "sel_fun_z_bins = (sel_fun_z[loc_29_54] - 0.05/2)[1:]\n",
    "\n",
    "zarr, magarr = np.meshgrid(sel_fun_z_act, sel_fun_imag)\n",
    "\n",
    "qlf_array = QLF_phi_app(magarr, zarr, **keywords)\n",
    "\n",
    "n_arr = sel_fun_array * qlf_array\n",
    "\n",
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v2(ra_col_shen, dec_col_shen, red_col_shen, 5, 10)\n",
    "plt.close()\n",
    "rand_red_col_shen = make_rand_from_n_m_z(n_arr, sel_fun_z_bins, len(rand_ra_col_shen))\n",
    "\n",
    "try_clustering_for_z_dist(rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a new random catalog with z distribution exactly same as data catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen = make_shen_random_catalog_v2(ra_col_shen, dec_col_shen, red_col_shen, 5, 10)\n",
    "plt.close()\n",
    "rand_red_col_shen = np.tile(red_col_shen, (10,1))\n",
    "rand_red_col_shen = rand_red_col_shen.flatten()\n",
    "np.random.shuffle(rand_red_col_shen)\n",
    "try_clustering_for_z_dist(rand_ra_col_shen, rand_dec_col_shen, rand_red_col_shen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the result that we got"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
